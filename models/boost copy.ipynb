{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "air_canada = pd.read_csv('../datasets/new_data.csv')\n",
    "\n",
    "# seperate dataset into training and predicting\n",
    "air_canada_to_predict = air_canada[air_canada['choice'] != air_canada['choice']]\n",
    "air_canada = air_canada[air_canada['choice'] == air_canada['choice']]\n",
    "\n",
    "X, y = air_canada.drop(['Unnamed: 0', 'id', 'ticket_id', 'choice'], axis=1), air_canada[['choice']]\n",
    "\n",
    "y['choice'] = y['choice'].map({ 'nochoice': 0, 'pref': 1, 'advs': 2 })\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = make_pipeline(\n",
    "  StandardScaler()\n",
    ")\n",
    "\n",
    "cat_pipeline = make_pipeline(\n",
    "  OneHotEncoder()\n",
    ")\n",
    "preprocessing = ColumnTransformer([\n",
    "    ('cat', cat_pipeline, ['od']),\n",
    "    ('num', num_pipeline, ['date_difference', 'trip_type', 'branded_fare', 'number_of_pax', 'ADVS_price', 'PREF_price',\n",
    "       'ADVS_capacity', 'PREF_capacity', 'ADVS_inventory', 'PREF_inventory'])\n",
    "  ], remainder='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prep = preprocessing.fit_transform(X_train)\n",
    "X_test_prep = preprocessing.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prep[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "bst = XGBClassifier(learning_rate=.3, objective='multi:softmax')\n",
    "bst.fit(X_train_prep, y_train)\n",
    "\n",
    "\n",
    "y_pred = bst.predict(X_test_prep)\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],           # Number of boosting rounds\n",
    "    'learning_rate': [0.01, 0.1, 0.2],         # Step size shrinkage\n",
    "    'max_depth': [3, 5, 7],                    # Maximum depth of the trees\n",
    "    'min_child_weight': [1, 3, 5],             # Minimum sum of instance weight needed in a child\n",
    "    'subsample': [0.6, 0.8, 1.0],              # Subsample ratio of the training instances\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],       # Subsample ratio of columns when constructing each tree\n",
    "    'gamma': [0, 0.1, 0.2],                    # Minimum loss reduction to make a further partition on a leaf node\n",
    "}\n",
    "\n",
    "rnd_search = GridSearchCV(bst,\n",
    "    param_grid=param_grid, verbose=3, cv=3, n_jobs=-1,\n",
    "    scoring='neg_root_mean_squared_error')\n",
    "\n",
    "rnd_search.fit(X_train_prep, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_to_predict, y_to_predict = air_canada_to_predict.drop(['id', 'ticket_id', 'choice'], axis=1), air_canada_to_predict[['id']]\n",
    "X_to_predict_prep = preprocessing.transform(X_to_predict)\n",
    "y_to_predict['choice'] = bst.predict(X_to_predict_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_to_predict['choice'] = y_to_predict['choice'].map({ 0: 'nochoice', 1: 'pref', 2: 'advs'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final = pd.concat([y_to_predict, air_canada])[['id', 'choice']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.to_csv(y_final, '../predictions/pred2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
