{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-5-sg3VK2mo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "air_canada = pd.read_csv('./new_branded_data.csv')\n",
        "air_canada = air_canada.dropna(subset=['choice'])\n",
        "\n",
        "y = air_canada['choice']\n",
        "X = air_canada.drop(['id', 'Unnamed: 0','flight_departure_datetime', 'purchase_datetime', 'ticket_id', 'choice'], axis=1)\n",
        "X = X.dropna()"
      ],
      "metadata": {
        "id": "mTX8JMWNRumc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data into train (80%), validation (10%), and test (10%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "Qp52IsVAR66M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.compose import ColumnTransformer, make_column_selector\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "num_pipeline = make_pipeline(\n",
        "  StandardScaler()\n",
        ")\n",
        "\n",
        "cat_pipeline = make_pipeline(\n",
        "  OneHotEncoder()\n",
        ")\n",
        "\n",
        "# Create the preprocessing transformer\n",
        "preprocessing = ColumnTransformer([\n",
        "    ('cat', cat_pipeline, ['od']),  # Only the 'od' column is categorical\n",
        "    ('num', num_pipeline, make_column_selector(dtype_exclude='object'))  # Select all non-categorical columns\n",
        "], remainder='drop')"
      ],
      "metadata": {
        "id": "m_BH5SLIZrIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_prep = preprocessing.fit_transform(X_train)\n",
        "X_val_prep = preprocessing.fit_transform(X_val)\n",
        "X_test_prep = preprocessing.transform(X_test)"
      ],
      "metadata": {
        "id": "fP-1JpL6Z8Tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode the y (choice) column\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# One-hot encode the y (choice) column\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "\n",
        "y_train_prep = encoder.fit_transform(pd.DataFrame(y_train))\n",
        "y_val_prep = encoder.fit_transform(pd.DataFrame(y_val))\n",
        "y_test_prep = encoder.fit_transform(pd.DataFrame(y_test))"
      ],
      "metadata": {
        "id": "4DzOBegNRtZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data to TensorFlow tensors\n",
        "X_train_tensor = tf.convert_to_tensor(X_train_prep, dtype=tf.float32)\n",
        "y_train_tensor = tf.convert_to_tensor(y_train_prep, dtype=tf.float32)\n",
        "X_val_tensor = tf.convert_to_tensor(X_val_prep, dtype=tf.float32)\n",
        "y_val_tensor = tf.convert_to_tensor(y_val_prep, dtype=tf.float32)\n",
        "X_test_tensor = tf.convert_to_tensor(X_test_prep, dtype=tf.float32)\n",
        "y_test_tensor = tf.convert_to_tensor(y_test_prep, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "kPuMy187SKzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.InputLayer(shape=(24,)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "V026ZvLQQe5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(optimizer='adam', activation='relu'):\n",
        "  model = tf.keras.Sequential([\n",
        "  tf.keras.layers.InputLayer(input_shape=(20,)),  # Input layer expecting 20 features per row\n",
        "  tf.keras.layers.Dense(64, activation=activation),\n",
        "  tf.keras.layers.Dense(32, activation=activation),\n",
        "  tf.keras.layers.Dense(3, activation='softmax')  # Output layer with 4 choices (assuming 4 classes in 'choice')\n",
        "  ])\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "7mSz3INhzuCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikeras"
      ],
      "metadata": {
        "id": "bgTEwcflzbOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "\n",
        "keras_classifier = KerasClassifier(model=create_model, verbose=0)\n",
        "\n",
        "# Define the hyperparameter grid for neural network\n",
        "param_grid = {\n",
        "    'model__optimizer': ['adam', 'sgd'],          # Optimizers to try\n",
        "    'model__activation': ['relu', 'tanh'],        # Activation functions for the hidden layers\n",
        "    'batch_size': [10, 20],                       # Batch sizes\n",
        "    'epochs': [10, 20],                           # Number of epochs\n",
        "}\n",
        "\n",
        "# GridSearchCV for KerasClassifier\n",
        "rnd_search = GridSearchCV(estimator=keras_classifier,\n",
        "                          param_grid=param_grid,\n",
        "                          scoring='accuracy',\n",
        "                          cv=3,\n",
        "                          verbose=3,\n",
        "                          n_jobs=-1)\n",
        "\n",
        "# Fit the model\n",
        "rnd_search.fit(X_train_prep, y_train_prep)\n",
        "\n",
        "# Print the best parameters and score\n",
        "print(f\"Best: {rnd_search.best_score_} using {rnd_search.best_params_}\")\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "best_model = rnd_search.best_estimator_\n",
        "test_accuracy = best_model.score(X_test, y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "tVHuX6nwyHuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X_train_tensor, y_train_tensor, epochs=20, validation_data=(X_val_tensor, y_val_tensor))\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(X_test_tensor, y_test_tensor)\n",
        "print(f\"Test accuracy: {test_accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "LUjaSwcQQ6iC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "air_canada_to_predict = pd.read_csv(\"new_branded_baseline.csv\")\n",
        "\n",
        "columns_to_drop = ['id',\n",
        "                   'Unnamed: 0',\n",
        "          'ticket_id',\n",
        "          'choice',\n",
        "          'flight_departure_datetime',\n",
        "          'purchase_datetime']\n",
        "X_to_predict, y_to_predict = air_canada_to_predict.drop(columns_to_drop, axis=1), air_canada_to_predict[['id']]"
      ],
      "metadata": {
        "id": "9wf4HXUGS1_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_to_predict_prep = preprocessing.fit_transform(X_to_predict)"
      ],
      "metadata": {
        "id": "6sz-AiuaXjfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_to_predict_prep)"
      ],
      "metadata": {
        "id": "AAkLZjjfe94K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: save prediction in a csv file with column named choice_prediction\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'prediction' is a NumPy array of predicted probabilities\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Create a DataFrame with the predictions\n",
        "results_df = pd.DataFrame({'choice_prediction': predicted_classes})\n",
        "\n",
        "# Concatenate the results with the original 'id' column\n",
        "results_df = pd.concat([y_to_predict, results_df], axis=1)\n",
        "\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "results_df.to_csv('prediction.csv', index=False)"
      ],
      "metadata": {
        "id": "5B_erD5egAgo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}